{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'C2T1_Train.csv'\n",
    " \n",
    "rawDF=pd.read_csv(filePath)\n",
    "\n",
    "rawDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Column has almost all '?' values renderring it useless for the model to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF.drop('weight', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop max_glu_serum & A1Cresult as it is mostly NuLL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF.drop('max_glu_serum', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF.drop('A1Cresult', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('C2T1_Train.csv')\n",
    "\n",
    "# Replace '?' with NaN\n",
    "df = df.replace('?', pd.NA)\n",
    "\n",
    "# Define columns again, ensuring we're working with the correct data types\n",
    "num_columns = [col for col in df.columns if df[col].dtype in ['int64', 'float64'] and col not in ['encounter_id2', 'patient_nbr2']]\n",
    "cat_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "# Impute missing values\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent', add_indicator=True)\n",
    "\n",
    "df[num_columns] = num_imputer.fit_transform(df[num_columns])\n",
    "# The categorical imputation needs to be handled differently to avoid the error.\n",
    "# Manually impute missing values for categorical columns\n",
    "for col in cat_columns:\n",
    "    # If a column is categorical, fill missing values with the mode (most frequent value)\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Proceed with OneHotEncoder for categorical variables\n",
    "onehot_encoder = OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore')\n",
    "encoded_features = onehot_encoder.fit_transform(df[cat_columns])\n",
    "encoded_features_df = pd.DataFrame(encoded_features, columns=onehot_encoder.get_feature_names_out(cat_columns))\n",
    "encoded_features_df.index = df.index  # Ensure alignment of indices\n",
    "\n",
    "# Remove original categorical columns and merge the encoded features\n",
    "df = df.drop(cat_columns, axis=1)\n",
    "df = pd.concat([df, encoded_features_df], axis=1)\n",
    "\n",
    "# Standardize numerical features (excluding identifiers)\n",
    "scaler = StandardScaler()\n",
    "df[num_columns] = scaler.fit_transform(df[num_columns])\n",
    "\n",
    "# Attempt to display the first few rows of the corrected DataFrame\n",
    "df.head()\n",
    "\n",
    "df.to_csv('cleandata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C2T1_Train.csv')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# List of specific columns to process\n",
    "columns_to_process = [\n",
    "    \"metformin\", \"repaglinide\", \"nateglinide\",\n",
    "    \"chlorpropamide\", \"glimepiride\", \"acetohexamide\", \"glipizide\", \"glyburide\",\n",
    "    \"tolbutamide\", \"pioglitazone\", \"rosiglitazone\", \"acarbose\", \"miglitol\",\n",
    "    \"troglitazone\", \"tolazamide\", \"examide\", \"citoglipton\",\n",
    "    \"glyburide-metformin\", \"glipizide-metformin\", \"glimepiride-pioglitazone\",\n",
    "    \"metformin-rosiglitazone\", \"metformin-pioglitazone\", \"change\", 'gender'\n",
    "]\n",
    "\n",
    "\n",
    "race_columns = [\"race\"]\n",
    "\n",
    "# Define a function to apply the conversion\n",
    "def convert_value(value):\n",
    "    if value is None or pd.isnull(value):\n",
    "        return value\n",
    "    value_lower = value.lower()\n",
    "    return 0 if value_lower in ['none', 'no', 'female'] else 1\n",
    "\n",
    "# Apply the function to the specified columns\n",
    "for column in columns_to_process:\n",
    "    if column in df.columns:  # Check if the column exists in the DataFrame\n",
    "        df[column] = df[column].apply(convert_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.drop('weight', axis=1, inplace=True)\n",
    "df.drop('max_glu_serum', axis=1, inplace=True)\n",
    "df.drop('A1Cresult', axis=1, inplace=True)\n",
    "\n",
    "# After processing, you might want to save the processed DataFrame or use it for further analysis\n",
    "df.to_csv('path_to_your_processed_csv_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race\n",
      "Caucasian          67515\n",
      "AfricanAmerican    17267\n",
      "?                   2207\n",
      "Hispanic            1834\n",
      "Other               1358\n",
      "Asian                585\n",
      "Name: count, dtype: int64\n",
      "race\n",
      "1.0    67515\n",
      "2.0    17267\n",
      "3.0     1834\n",
      "4.0     1358\n",
      "5.0      585\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('path_to_your_processed_csv_file.csv')\n",
    "race_value_counts = df['race'].value_counts()\n",
    "print(race_value_counts)\n",
    "\n",
    "\n",
    "# Define your race mapping\n",
    "race_mapping = {\n",
    "    'Caucasian': 1,\n",
    "    'AfricanAmerican': 2,\n",
    "    'Hispanic': 3,\n",
    "    'Other': 4,\n",
    "    'Asian': 5,\n",
    "    '?': np.nan  # Use NaN for unknown values\n",
    "}\n",
    "\n",
    "# Map the race values in your DataFrame\n",
    "df['race'] = df['race'].map(race_mapping)\n",
    "\n",
    "\n",
    "# Verify the changes\n",
    "race_value_counts2= df['race'].value_counts()\n",
    "print(race_value_counts2)\n",
    "\n",
    "df.to_csv('path_to_your_processed_csv_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical_specialty\n",
      "?                                       43674\n",
      "InternalMedicine                        13657\n",
      "Family/GeneralPractice                   6906\n",
      "Emergency/Trauma                         6398\n",
      "Cardiology                               4939\n",
      "Surgery-General                          2778\n",
      "Nephrology                               1457\n",
      "Orthopedics                              1234\n",
      "Orthopedics-Reconstructive               1137\n",
      "Radiologist                               966\n",
      "Pulmonology                               814\n",
      "Psychiatry                                774\n",
      "Urology                                   627\n",
      "Surgery-Cardiovascular/Thoracic           623\n",
      "ObstetricsandGynecology                   619\n",
      "Gastroenterology                          484\n",
      "Surgery-Neuro                             446\n",
      "Surgery-Vascular                          416\n",
      "PhysicalMedicineandRehabilitation         383\n",
      "Oncology                                  314\n",
      "Pediatrics                                239\n",
      "Hematology/Oncology                       205\n",
      "Neurology                                 172\n",
      "Pediatrics-Endocrinology                  159\n",
      "Endocrinology                             120\n",
      "Otolaryngology                            117\n",
      "Surgery-Thoracic                          100\n",
      "Pediatrics-CriticalCare                    87\n",
      "Surgery-Cardiovascular                     85\n",
      "Psychology                                 83\n",
      "Podiatry                                   80\n",
      "Hematology                                 72\n",
      "Gynecology                                 54\n",
      "Radiology                                  53\n",
      "Hospitalist                                44\n",
      "Surgeon                                    44\n",
      "Surgery-Plastic                            34\n",
      "InfectiousDiseases                         34\n",
      "Osteopath                                  33\n",
      "SurgicalSpecialty                          32\n",
      "Ophthalmology                              31\n",
      "Pediatrics-Pulmonology                     25\n",
      "Obsterics&Gynecology-GynecologicOnco       25\n",
      "Anesthesiology-Pediatric                   19\n",
      "Pathology                                  17\n",
      "Obstetrics                                 14\n",
      "Rheumatology                               14\n",
      "Anesthesiology                             12\n",
      "Surgery-Colon&Rectal                       11\n",
      "Surgery-Maxillofacial                      10\n",
      "OutreachServices                           10\n",
      "Pediatrics-Neurology                       10\n",
      "PhysicianNotFound                           9\n",
      "Surgery-Pediatric                           8\n",
      "Endocrinology-Metabolism                    8\n",
      "AllergyandImmunology                        7\n",
      "Psychiatry-Child/Adolescent                 7\n",
      "Cardiology-Pediatric                        6\n",
      "DCPTEAM                                     6\n",
      "Dentistry                                   4\n",
      "Pediatrics-Hematology-Oncology              4\n",
      "Pediatrics-AllergyandImmunology             3\n",
      "Pediatrics-EmergencyMedicine                3\n",
      "Resident                                    2\n",
      "Proctology                                  1\n",
      "Psychiatry-Addictive                        1\n",
      "Dermatology                                 1\n",
      "SportsMedicine                              1\n",
      "Speech                                      1\n",
      "Pediatrics-InfectiousDiseases               1\n",
      "Neurophysiology                             1\n",
      "Surgery-PlasticwithinHeadandNeck            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('path_to_your_processed_csv_file.csv')\n",
    "# Set pandas to display all rows when printing the value counts\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Get the value counts of the 'medical_specialty' column\n",
    "medical_specialty_value_counts = df['medical_specialty'].value_counts()\n",
    "\n",
    "# Print all the value counts\n",
    "print(medical_specialty_value_counts)\n",
    "medical_specialty_value_counts.to_csv('medical_specialty_value_counts.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path_to_your_processed_csv_file.csv')\n",
    "\n",
    "df.drop('medical_specialty', axis=1, inplace=True)\n",
    "\n",
    "df.to_csv('path_to_your_processed_csv_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encounter_id2  patient_nbr2  race  gender  age  admission_type_id   \n",
      "0           5283      48330653   1.0       0   85                  2  \\\n",
      "1           8499      63555809   1.0       0   95                  3   \n",
      "2           9441      42519137   1.0       1   45                  1   \n",
      "3          20997      89868902   2.0       0   45                  1   \n",
      "4          28515      82637321   1.0       1   55                  2   \n",
      "\n",
      "   discharge_disposition_id  admission_source_id  time_in_hospital payer_code   \n",
      "0                         1                    4                13          ?  \\\n",
      "1                         3                    4                12          ?   \n",
      "2                         1                    7                 1          ?   \n",
      "3                         1                    7                 9          ?   \n",
      "4                         1                    2                 3          ?   \n",
      "\n",
      "   ...  citoglipton  insulin  glyburide-metformin  glipizide-metformin   \n",
      "0  ...            0   Steady                    0                    0  \\\n",
      "1  ...            0   Steady                    0                    0   \n",
      "2  ...            0   Steady                    0                    0   \n",
      "3  ...            0   Steady                    0                    0   \n",
      "4  ...            0   Steady                    0                    0   \n",
      "\n",
      "   glimepiride-pioglitazone  metformin-rosiglitazone metformin-pioglitazone   \n",
      "0                         0                        0                      0  \\\n",
      "1                         0                        0                      0   \n",
      "2                         0                        0                      0   \n",
      "3                         0                        0                      0   \n",
      "4                         0                        0                      0   \n",
      "\n",
      "  change diabetesMed  readmitted  \n",
      "0      1         Yes          NO  \n",
      "1      1         Yes          NO  \n",
      "2      1         Yes          NO  \n",
      "3      0         Yes         >30  \n",
      "4      0         Yes         >30  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "def convert_age(age_range):\n",
    "    lower, upper = age_range[1:-1].split('-')\n",
    "    midpoint = (int(lower) + int(upper)) // 2\n",
    "    return midpoint\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('path_to_your_processed_csv_file.csv')\n",
    "\n",
    "# Apply the conversion function to the 'age' column\n",
    "df['age'] = df['age'].apply(convert_age)\n",
    "\n",
    "# Display the first few rows to ensure the conversion worked as expected\n",
    "print(df.head())\n",
    "\n",
    "# Save the processed DataFrame back to a new CSV file\n",
    "df.to_csv('path_to_your_processed_csv_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path_to_your_processed_csv_file.csv')\n",
    "scaler = StandardScaler()\n",
    "num_columns = [col for col in df.columns if df[col].dtype in ['int64', 'float64'] and col not in ['encounter_id2', 'patient_nbr2']]\n",
    "df[num_columns] = scaler.fit_transform(df[num_columns])\n",
    "df.to_csv('path_to_your_processed_csv_file1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmitted\n",
      "0    49361\n",
      "1    41405\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('path_to_your_processed_csv_file1.csv')\n",
    "\n",
    "\n",
    "# Convert 'readmitted' values: 0 for 'NO', 1 for any other value\n",
    "df['readmitted'] = df['readmitted'].apply(lambda x: 0 if x == 'NO' else 1)\n",
    "\n",
    "# Save the modified DataFrame back to a CSV if needed\n",
    "df.to_csv('path_to_your_processed_csv_file1.csv', index=False)\n",
    "\n",
    "# Verify the changes\n",
    "print(df['readmitted'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path_to_your_processed_csv_file.csv')\n",
    "\n",
    "df.drop('payer_code', axis=1, inplace=True)\n",
    "\n",
    "df.to_csv('path_to_your_processed_csv_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encounter_id2  patient_nbr2      race    gender       age   \n",
      "0           5283      48330653 -0.473075 -0.928409  1.195421  \\\n",
      "1           8499      63555809 -0.473075 -0.928409  1.820909   \n",
      "2           9441      42519137 -0.473075  1.077112 -1.306535   \n",
      "3          20997      89868902  1.058792 -0.928409 -1.306535   \n",
      "4          28515      82637321 -0.473075  1.077112 -0.681046   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id   \n",
      "0          -0.017468                 -0.517817            -0.445388  \\\n",
      "1           0.670080                 -0.144628            -0.445388   \n",
      "2          -0.705015                 -0.517817             0.277931   \n",
      "3          -0.705015                 -0.517817             0.277931   \n",
      "4          -0.017468                 -0.517817            -0.927601   \n",
      "\n",
      "   time_in_hospital payer_code  ...  citoglipton  insulin   \n",
      "0          2.867647          ?  ...          0.0   Steady  \\\n",
      "1          2.533853          ?  ...          0.0   Steady   \n",
      "2         -1.137886          ?  ...          0.0   Steady   \n",
      "3          1.532469          ?  ...          0.0   Steady   \n",
      "4         -0.470297          ?  ...          0.0   Steady   \n",
      "\n",
      "   glyburide-metformin  glipizide-metformin  glimepiride-pioglitazone   \n",
      "0            -0.079285            -0.009389                 -0.003319  \\\n",
      "1            -0.079285            -0.009389                 -0.003319   \n",
      "2            -0.079285            -0.009389                 -0.003319   \n",
      "3            -0.079285            -0.009389                 -0.003319   \n",
      "4            -0.079285            -0.009389                 -0.003319   \n",
      "\n",
      "   metformin-rosiglitazone metformin-pioglitazone    change diabetesMed   \n",
      "0                -0.004694              -0.003319  1.099012         Yes  \\\n",
      "1                -0.004694              -0.003319  1.099012         Yes   \n",
      "2                -0.004694              -0.003319  1.099012         Yes   \n",
      "3                -0.004694              -0.003319 -0.909908         Yes   \n",
      "4                -0.004694              -0.003319 -0.909908         Yes   \n",
      "\n",
      "   readmitted  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           1  \n",
      "4           1  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame from the CSV file\n",
    "df = pd.read_csv('path_to_your_processed_csv_file1.csv')\n",
    "\n",
    "# Replace all NaN values with 0s\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Verify the changes by displaying the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "df.to_csv('path_to_your_processed_csv_file1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('path_to_your_processed_csv_file1.csv')\n",
    "\n",
    "# Specified attributes to include as features\n",
    "features = [\n",
    "    \"race\", \"gender\", \"age\", \"admission_type_id\", \"discharge_disposition_id\",\n",
    "    \"admission_source_id\", \"time_in_hospital\", \"payer_code\", \"num_lab_procedures\",\n",
    "    \"num_procedures\", \"num_medications\", \"number_outpatient\", \"number_emergency\",\n",
    "    \"number_inpatient\", \"diag_1\", \"diag_2\", \"diag_3\", \"number_diagnoses\",\n",
    "    \"metformin\", \"repaglinide\", \"nateglinide\", \"chlorpropamide\", \"glimepiride\",\n",
    "    \"acetohexamide\", \"glipizide\", \"glyburide\", \"tolbutamide\", \"pioglitazone\",\n",
    "    \"rosiglitazone\", \"acarbose\", \"miglitol\", \"troglitazone\", \"tolazamide\",\n",
    "    \"examide\", \"citoglipton\", \"insulin\", \"glyburide-metformin\", \"glipizide-metformin\",\n",
    "    \"glimepiride-pioglitazone\", \"metformin-rosiglitazone\", \"metformin-pioglitazone\",\n",
    "    \"change\", \"diabetesMed\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['readmitted']  # Target variable\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing for numerical and categorical data\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "# Numerical transformer with StandardScaler and optional PCA\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95))  # Keeps 95% of variance\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "    ])\n",
    "\n",
    "# SVM model pipeline\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "# Training the SVM model\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
